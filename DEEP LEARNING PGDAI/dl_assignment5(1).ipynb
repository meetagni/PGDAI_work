{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtX3C7T_EqAG",
        "outputId": "9804cef2-c19e-4076-cee6-843302fb9e6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "1X8_7Ts3Fw58",
        "outputId": "ce8abc28-c653-42b8-8997-03e2b0c1d6a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f48993b-5ea3-4e75-95ea-42fb139c97d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3f48993b-5ea3-4e75-95ea-42fb139c97d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"meetag\",\"key\":\"e7cdeb910da14ab1b70f8579e5faf8a6\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uEyC7BaF8Fe",
        "outputId": "0ccfb51d-a661-42e0-c70a-e31882ef7e3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWnHunPaGB52",
        "outputId": "3d206f37-16cd-45ad-d998-eebb0e6df19b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intel-image-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip intel-image-classification.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UDAe5l4GM7-",
        "outputId": "439d4db6-42d6-47f1-bcc5-31c9aca165b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  intel-image-classification.zip\n",
            "replace seg_pred/seg_pred/10004.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras\n",
        "import matplotlib.gridspec as gridspec\n",
        "from random import randint\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "BN3F4NyCHtf_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ],
      "metadata": {
        "id": "HGlPmQnrH87q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    for dir in os.listdir(directory):\n",
        "        label = -1\n",
        "        if(dir == \"buildings\"):\n",
        "            label = 0\n",
        "        if(dir == \"forest\"):\n",
        "            label = 1\n",
        "        if(dir == \"glacier\"):\n",
        "            label = 2\n",
        "        if(dir == \"mountain\"):\n",
        "            label = 3\n",
        "        if(dir == \"sea\"):\n",
        "            label = 4\n",
        "        if(dir == \"street\"):\n",
        "            label = 5\n",
        "        for image_dir in os.listdir(directory +\"//\"+ dir):\n",
        "            image = cv2.imread(directory +\"//\"+ dir + \"//\"+ image_dir)\n",
        "            image = cv2.resize(image, (150,150))\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "    return shuffle(images, labels)"
      ],
      "metadata": {
        "id": "v9oE9lsSG1ZN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = get_images(\"/content/seg_train/seg_train\")\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "dR71R72THng0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height=img_width=150\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(img_height, \n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "xCA6vXkYHpzm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw953jk_IC4G",
        "outputId": "407a0f1a-79fe-4c07-fe23-ddf7f9912db5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = to_categorical(labels)\n",
        "images = images.astype('float32')\n",
        "images /= 255.0"
      ],
      "metadata": {
        "id": "kHYHXziTIg7d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(data_augmentation)\n",
        "model.add(layers.Conv2D(filters = 64, kernel_size=(7,7), strides=(2,2), activation='relu', input_shape=(150,150,3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128,kernel_size=(3,3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=156, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(72, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(6, activation='softmax'))"
      ],
      "metadata": {
        "id": "BvU1CR9mIyGd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-hQIplFI5kl",
        "outputId": "f90967e4-372b-45f6-82c6-595b7bba387e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 72, 72, 64)        9472      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 72, 72, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 35, 35, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 35, 35, 96)        55392     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 35, 35, 96)       384       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 17, 17, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 17, 17, 128)       110720    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 17, 17, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 156)         80028     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 156)        624       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 3, 156)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1404)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               179840    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 72)                9288      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 72)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 438       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 446,954\n",
            "Trainable params: 446,066\n",
            "Non-trainable params: 888\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained = model.fit(images, labels, epochs =64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91vg-qHxJGhF",
        "outputId": "30753154-ac35-4a77-d205-62a950036648"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "439/439 [==============================] - 27s 40ms/step - loss: 1.4956 - accuracy: 0.4249\n",
            "Epoch 2/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 1.1768 - accuracy: 0.5545\n",
            "Epoch 3/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 1.0756 - accuracy: 0.6059\n",
            "Epoch 4/64\n",
            "439/439 [==============================] - 16s 38ms/step - loss: 1.0034 - accuracy: 0.6365\n",
            "Epoch 5/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.9267 - accuracy: 0.6728\n",
            "Epoch 6/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.9104 - accuracy: 0.6845\n",
            "Epoch 7/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.8599 - accuracy: 0.6985\n",
            "Epoch 8/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.8317 - accuracy: 0.7115\n",
            "Epoch 9/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.7851 - accuracy: 0.7306\n",
            "Epoch 10/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.7582 - accuracy: 0.7455\n",
            "Epoch 11/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.7456 - accuracy: 0.7498\n",
            "Epoch 12/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.7261 - accuracy: 0.7534\n",
            "Epoch 13/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.6935 - accuracy: 0.7701\n",
            "Epoch 14/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.6802 - accuracy: 0.7735\n",
            "Epoch 15/64\n",
            "439/439 [==============================] - 17s 40ms/step - loss: 0.6599 - accuracy: 0.7840\n",
            "Epoch 16/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.6254 - accuracy: 0.7944\n",
            "Epoch 17/64\n",
            "439/439 [==============================] - 18s 40ms/step - loss: 0.6168 - accuracy: 0.7935\n",
            "Epoch 18/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.6065 - accuracy: 0.7938\n",
            "Epoch 19/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.6146 - accuracy: 0.7944\n",
            "Epoch 20/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5895 - accuracy: 0.8060\n",
            "Epoch 21/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5668 - accuracy: 0.8117\n",
            "Epoch 22/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5625 - accuracy: 0.8134\n",
            "Epoch 23/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5401 - accuracy: 0.8216\n",
            "Epoch 24/64\n",
            "439/439 [==============================] - 16s 38ms/step - loss: 0.5387 - accuracy: 0.8256\n",
            "Epoch 25/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5195 - accuracy: 0.8301\n",
            "Epoch 26/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5174 - accuracy: 0.8277\n",
            "Epoch 27/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5193 - accuracy: 0.8341\n",
            "Epoch 28/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.5054 - accuracy: 0.8353\n",
            "Epoch 29/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4903 - accuracy: 0.8358\n",
            "Epoch 30/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4869 - accuracy: 0.8391\n",
            "Epoch 31/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4868 - accuracy: 0.8365\n",
            "Epoch 32/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4696 - accuracy: 0.8434\n",
            "Epoch 33/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4684 - accuracy: 0.8468\n",
            "Epoch 34/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4569 - accuracy: 0.8489\n",
            "Epoch 35/64\n",
            "439/439 [==============================] - 17s 40ms/step - loss: 0.4667 - accuracy: 0.8400\n",
            "Epoch 36/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4440 - accuracy: 0.8499\n",
            "Epoch 37/64\n",
            "439/439 [==============================] - 18s 40ms/step - loss: 0.4443 - accuracy: 0.8540\n",
            "Epoch 38/64\n",
            "439/439 [==============================] - 16s 38ms/step - loss: 0.4473 - accuracy: 0.8541\n",
            "Epoch 39/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.4320 - accuracy: 0.8585\n",
            "Epoch 40/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4374 - accuracy: 0.8568\n",
            "Epoch 41/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4206 - accuracy: 0.8581\n",
            "Epoch 42/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4139 - accuracy: 0.8621\n",
            "Epoch 43/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4260 - accuracy: 0.8560\n",
            "Epoch 44/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4026 - accuracy: 0.8691\n",
            "Epoch 45/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.4007 - accuracy: 0.8653\n",
            "Epoch 46/64\n",
            "439/439 [==============================] - 16s 38ms/step - loss: 0.3973 - accuracy: 0.8699\n",
            "Epoch 47/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3921 - accuracy: 0.8729\n",
            "Epoch 48/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3981 - accuracy: 0.8694\n",
            "Epoch 49/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3727 - accuracy: 0.8765\n",
            "Epoch 50/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3844 - accuracy: 0.8740\n",
            "Epoch 51/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3757 - accuracy: 0.8739\n",
            "Epoch 52/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3749 - accuracy: 0.8730\n",
            "Epoch 53/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3628 - accuracy: 0.8788\n",
            "Epoch 54/64\n",
            "439/439 [==============================] - 16s 37ms/step - loss: 0.3668 - accuracy: 0.8784\n",
            "Epoch 55/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3649 - accuracy: 0.8775\n",
            "Epoch 56/64\n",
            "439/439 [==============================] - 18s 40ms/step - loss: 0.3699 - accuracy: 0.8782\n",
            "Epoch 57/64\n",
            "439/439 [==============================] - 18s 40ms/step - loss: 0.3598 - accuracy: 0.8801\n",
            "Epoch 58/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3588 - accuracy: 0.8809\n",
            "Epoch 59/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3541 - accuracy: 0.8781\n",
            "Epoch 60/64\n",
            "439/439 [==============================] - 20s 45ms/step - loss: 0.3516 - accuracy: 0.8839\n",
            "Epoch 61/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3515 - accuracy: 0.8824\n",
            "Epoch 62/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3426 - accuracy: 0.8818\n",
            "Epoch 63/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3440 - accuracy: 0.8846\n",
            "Epoch 64/64\n",
            "439/439 [==============================] - 17s 38ms/step - loss: 0.3365 - accuracy: 0.8885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = get_images('/content/seg_test/seg_test')"
      ],
      "metadata": {
        "id": "pDs7-s33aapY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "test_images = test_images.astype('float32')\n",
        "test_images /= 255.0"
      ],
      "metadata": {
        "id": "zLAV3Ze5aiFr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_images, pred_labels = get_images('/content/seg_pred')\n",
        "pred_images = np.array(pred_images)"
      ],
      "metadata": {
        "id": "hogUgRykaogK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Session crashed after using all RAM"
      ],
      "metadata": {
        "id": "Y2HwimDua5aa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import classification_report\n",
        "#print(classification_report(test_labels,pred_images))"
      ],
      "metadata": {
        "id": "c_nNqJVhbK9c"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}